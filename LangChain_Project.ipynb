{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e4ab21bb-efd7-426a-b845-9491efaf52e3",
   "metadata": {},
   "source": [
    "# Create a Q&A Chatbot with LangChain Project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c96b4cd1-826e-42d0-914d-166ab7d2fa6b",
   "metadata": {},
   "source": [
    "### Set the OpenAI API Key as an Environment Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc2d63d7-172f-4aff-a9b8-495aca6396ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext dotenv\n",
    "%dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "816561e8-f742-4347-bc7e-0a21b07d2705",
   "metadata": {},
   "source": [
    "### Import the Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9db4fc20-609b-4066-900a-3050cb80783a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders.pdf import PyPDFLoader\n",
    "\n",
    "from langchain_text_splitters import (MarkdownHeaderTextSplitter, \n",
    "                                      TokenTextSplitter)\n",
    "\n",
    "from langchain_core.output_parsers.string import StrOutputParser\n",
    "from langchain_core.messages import SystemMessage\n",
    "from langchain_core.prompts import (PromptTemplate,\n",
    "                                    HumanMessagePromptTemplate, \n",
    "                                    ChatPromptTemplate)\n",
    "from langchain_core.runnables import (RunnablePassthrough, \n",
    "                                      RunnableLambda, \n",
    "                                      chain)\n",
    "\n",
    "from langchain_openai import (ChatOpenAI, \n",
    "                              OpenAIEmbeddings)\n",
    "\n",
    "from langchain_chroma.vectorstores import Chroma"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfa29c72",
   "metadata": {},
   "source": [
    "### Load the Course Transcript"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78cefcca-f280-42fc-821d-b0cee98bdead",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader_pdf = PyPDFLoader(\"Introduction_to_Tableau.pdf\")\n",
    "docs_list = loader_pdf.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11df1f5b-f8e4-4086-824c-98ec50bfa758",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "len(docs_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7f31df6-4035-4ca2-906e-319b1cf57de3",
   "metadata": {},
   "outputs": [],
   "source": [
    "string_list_concat = \"\".join([i.page_content for i in docs_list])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0d2134a",
   "metadata": {},
   "outputs": [],
   "source": [
    "string_list_concat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6cad7f0",
   "metadata": {},
   "source": [
    "### Split the Course Transcript with MarkdownHeaderTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "240ddc1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "md_splitter = MarkdownHeaderTextSplitter(\n",
    "    headers_to_split_on = [(\"#\", \"Section Title\"),\n",
    "                           (\"##\", \"Lecture Title\")]\n",
    ")\n",
    "\n",
    "docs_list_md_split = md_splitter.split_text(string_list_concat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb00c463",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "len(docs_list_md_split)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30478d0f",
   "metadata": {},
   "source": [
    "### Create a Chain to Correct the Course Transcript"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8ca5fb5-1a22-4472-a48b-851dd0a9c733",
   "metadata": {},
   "outputs": [],
   "source": [
    "string_list_split = [i.page_content for i in docs_list_md_split]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66e11ea6-5d15-49ad-964f-3c150787317a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "string_list_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75d304c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROMPT_FORMATTING_S = '''Improve the following Tableau lecture transcript by:\n",
    "- Splitting the text into meaningful paragraphs\n",
    "- Correcting any misplaced punctuation\n",
    "- Fixing mistranscribed words (e.g., changing 'tableaux' to 'Tableau')\"\n",
    "'''\n",
    "\n",
    "PROMPT_TEMPLATE_FORMATTING_H = '''This is the transcript:\n",
    "{lecture_transcript}\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b90e779-12cb-4c0b-b33f-38afacd634e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_formatting_s = SystemMessage(content=PROMPT_FORMATTING_S)\n",
    "prompt_template_formatting_h = HumanMessagePromptTemplate.from_template(template=PROMPT_TEMPLATE_FORMATTING_H)\n",
    "\n",
    "chat_prompt_template_formatting = ChatPromptTemplate(messages=[prompt_formatting_s, \n",
    "                                                               prompt_template_formatting_h])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3293c74-ad9f-4206-9105-7a6809269206",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat = ChatOpenAI(model_name='gpt-4o', \n",
    "                  seed=365,\n",
    "                  temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70f2c93e",
   "metadata": {},
   "outputs": [],
   "source": [
    "str_output_parser = StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beeb2041",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain_formatting = (chat_prompt_template_formatting \n",
    "                    | chat\n",
    "                    | str_output_parser)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24896acd",
   "metadata": {},
   "outputs": [],
   "source": [
    "string_list_formatted = chain_formatting.batch(string_list_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6822f05-2db3-424a-a47a-216d8a9d44e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "string_list_formatted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26aaa8f0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in string_list_formatted:\n",
    "    print(i)\n",
    "    print('''\n",
    "-------------------\n",
    "    ''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "852deccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, j in zip(docs_list_md_split, string_list_formatted):\n",
    "    i.page_content = j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de652a59",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in docs_list_md_split:\n",
    "    print(i.page_content)\n",
    "    print('''\n",
    "-------------------\n",
    "    ''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72702001",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(docs_list_md_split)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d7ce01f-d8d4-4adf-8184-6e1c61d35bf3",
   "metadata": {},
   "source": [
    "### Split the Lectures with TokenTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c28555be-fe0e-430d-9944-c35da545c82c",
   "metadata": {},
   "outputs": [],
   "source": [
    "token_splitter = TokenTextSplitter(encoding_name=\"cl100k_base\", \n",
    "                                   chunk_size=500, \n",
    "                                   chunk_overlap=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54c5c92b-e85f-43c3-a52e-0d622c21a333",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs_list_tokens_split = token_splitter.split_documents(docs_list_md_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bd31047-5292-477c-bbaa-b59a37183e4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(docs_list_tokens_split)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d2edb97",
   "metadata": {},
   "source": [
    "### Create Embeddings, Vector Store, and Retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42b1488a",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding = OpenAIEmbeddings(model='text-embedding-3-small')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5378ec56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vectorstore = Chroma.from_documents(documents = docs_list_tokens_split, \n",
    "#                                     embedding = embedding, \n",
    "#                                     persist_directory = \"./intro-to-tableau\")\n",
    "\n",
    "vectorstore = Chroma(persist_directory = \"./intro-to-tableau\", \n",
    "                     embedding_function = embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21448a5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(vectorstore.get()[\"documents\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eef0a861",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vectorstore.as_retriever(search_type = 'mmr', \n",
    "                                     search_kwargs = {'k':2, \n",
    "                                                      'lambda_mult':0.7})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45465253-b425-4074-a268-30c02064bdc5",
   "metadata": {},
   "source": [
    "### Create Prompts and Prompt Templates for the Q&A Chatbot Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64c5823d",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROMPT_CREATING_QUESTION = '''Lecture: {question_lecture}\n",
    "Title: {question_title}\n",
    "Body: {question_body}'''\n",
    "\n",
    "PROMPT_RETRIEVING_S = '''You will receive a question from a student taking a Tableau course, which includes a title and a body. \n",
    "The corresponding lecture will also be provided.\n",
    "\n",
    "Answer the question using only the provided context.\n",
    "\n",
    "At the end of your response, include the section and lecture names where the context was drawn from, formatted as follows: \n",
    "Resources: \n",
    "Section: *Section Title*, Lecture: *Lecture Title* \n",
    "...\n",
    "Replace *Section Title* and *Lecture Title* with the appropriate titles.'''\n",
    "\n",
    "PROMPT_TEMPLATE_RETRIEVING_H = '''This is the question:\n",
    "{question}\n",
    "\n",
    "This is the context:\n",
    "{context}'''\n",
    "\n",
    "prompt_creating_question = PromptTemplate.from_template(template=PROMPT_CREATING_QUESTION)\n",
    "prompt_retrieving_s = SystemMessage(content=PROMPT_RETRIEVING_S)\n",
    "prompt_template_retrieving_h = HumanMessagePromptTemplate.from_template(template=PROMPT_TEMPLATE_RETRIEVING_H)\n",
    "\n",
    "chat_prompt_template_retrieving = ChatPromptTemplate([prompt_retrieving_s, \n",
    "                                                      prompt_template_retrieving_h])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4f24135-77cc-47cb-af41-bc2d4fa8d52a",
   "metadata": {},
   "source": [
    "### Create the First Version of the Q&A Chatbot Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f57ff444-675e-4d77-a856-6d0fa535252f",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain_retrieving = (prompt_creating_question\n",
    "                    | RunnableLambda(lambda x: x.text)\n",
    "                    | {'context': retriever,\n",
    "                       'question': RunnablePassthrough()}\n",
    "                    | chat_prompt_template_retrieving \n",
    "                    | chat\n",
    "                    | str_output_parser)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68bfec1f-8a2a-4603-b310-d4b43241db51",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = chain_retrieving.invoke({\"question_lecture\": \"Adding a custom calculation\",\n",
    "                                  \"question_title\": \"Why are we using SUM here? It's unclear to me.\",\n",
    "                                  \"question_body\": \"This question refers to calculating the GM%.\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abc59d3c-a110-4f8b-9a23-516ef99d5089",
   "metadata": {},
   "outputs": [],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "523192d0-3359-46d2-9793-5d787017891c",
   "metadata": {},
   "source": [
    "### Create a Runnable Function to Format the Context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ada2aa9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "@chain\n",
    "def format_context(dictionary):\n",
    "    \n",
    "    formatted_string = \"\"\n",
    "    retrieved_list = dictionary[\"context\"]\n",
    "    \n",
    "    for i in range(len(retrieved_list)):\n",
    "        formatted_string += f'''\n",
    "Document {i+1}\n",
    "Section Title: {retrieved_list[i].metadata[\"Section Title\"]}\n",
    "Lecture Title: {retrieved_list[i].metadata[\"Lecture Title\"]}\n",
    "Content: {retrieved_list[i].page_content}\n",
    "\n",
    "-------------------\n",
    "'''\n",
    "        \n",
    "    new_dictionary = {\"context\": formatted_string, \n",
    "                      \"question\": dictionary[\"question\"]}\n",
    "    \n",
    "    return new_dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73fef0e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain_retrieving_improved = (prompt_creating_question \n",
    "                             | RunnableLambda(lambda x: x.text)\n",
    "                             | {'context': retriever,\n",
    "                                'question': RunnablePassthrough()} \n",
    "                             | format_context\n",
    "                             | chat_prompt_template_retrieving\n",
    "                             | chat\n",
    "                             | str_output_parser)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9198ec3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_improved = chain_retrieving_improved.invoke({\"question_lecture\": \"Adding a custom calculation\",\n",
    "                                                    \"question_title\": \"Why are we using SUM here? It's unclear to me.\",\n",
    "                                                    \"question_body\": \"This question refers to calculating the GM%.\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "935e8de2-a736-41ed-acfc-04addefd913c",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_improved"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92b19713-7830-4f6e-a424-3b8588d43efe",
   "metadata": {},
   "source": [
    "### Stream the Response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01a64d90-f212-40b0-8d0d-a1cf90fceddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_streamed = chain_retrieving_improved.stream({\"question_lecture\": \"Adding a custom calculation\",\n",
    "                                                    \"question_title\": \"Why are we using SUM here? It's unclear to me.\",\n",
    "                                                    \"question_body\": \"This question refers to calculating the GM%.\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "666333e8-a79a-4de3-bada-15ada2f3644c",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_streamed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "527f8838",
   "metadata": {},
   "outputs": [],
   "source": [
    "for chunk in result_streamed:\n",
    "    print(chunk, end=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb0984c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02873ff3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f52db99b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bca3aaab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c88298d1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain_env_project",
   "language": "python",
   "name": "langchain_env_project"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
